---
title: "Causal Inference in Statistics: A Primer. Preliminaries"
author: "Joel Parker"
date: "2023-08-14"
link-citations: true
categories: [Statistics, Causal-Inference]
---

## Introduction

A few months ago an advisor of mine mentioned some of the brilliant work that was being done in the of causal inference. This was not the first time I had heard about causal inference and it was probably closer to the 25th, but as a PhD student with a full course load and a job, it was hard to find the time to dive into this area of statistics. Recently, I purchased the Book of Why by Judea Peal. My idea was to read this book as a form of "light" reading after a long day of class to help introduce me to some of the ideas within causal inference, after all, The Book of Why was written by Peal to introduce these ideas to a general audience. However, after the first chapter I found myself getting excited about the topic and wanting to learn more. I decided I needed to find a reference that was more intended for someone like me. Specifically, I wanted to see some formulas. I don't know how I got to be this way but here I am, and a book, filled with text, filled with jargon, is now my preferred method of learning. Congratulations academia, the transformation is complete.

Fast forward to now. I have completed my course work, working part time, and I am waiting for may adviser to get back leave so I can complete my comps. Please, don't get me wrong, I still have PLENTY of work to do like writing my proposal, writing papers and studying for comps. However, I do believe that taking some time to expand my knowledge about an area of a field which I am getting a PhD in, is time well spent and who knows, maybe this could turn into part of my dissertation. Sounds like a win-win.

The first book I will be reading is "Causal inference in statistics: a primer" by Judea Pearl, Madelyn Glymour, and Nicholas Jewell. This blog with serve as a way to me to take notes and refine my understanding about the topics discussed in this book.

## Why Study Causation?

One of the questions tackled first section of this book is, what can the concept of causation, considered on it own, tell us about the world that tried and true statistical methods can not? If causation is well defined on it's own, then we can use causation as an addition/addendum to traditional statistics. When used together, causal inference can uncover the workings of the world that traditional methods can not.

## Simpsons Paradox

Simpsons paradox is discussed to introduce a motivation for causal inference. Statisticians are familiar with this paradox and Simpsons happens to be one of my favorite paradoxes to bring up with non-statistical friends. The idea that something can be good for men, good for woman and bad for the population, is allays mind boggling to people and to my myself. However, the authors did not just pull from a bag of clever examples just to demonstrate the importance of stratifying to help research make decisions about treatment effects. They demonstrated two examples which had opposite conclusions, despite having the same values after stratification.

Consider example 1, where recovery rates were recorded of 700 patients after taking a drug. A total of 350 patients took the drug and 350 patients did not and the gender of each person was also recorded.

|           | Drug                           | No Drug                        |
|-----------|--------------------------------|--------------------------------|
| **Men**   | 81 out of 87 recovered (93%)   | 234 out of 270 recovered (87%) |
| **Woman** | 192 out of 263 recovered (73%) | 55 out of 80 recovered (69%)   |
| **Total** | 273 out of 350 recovered (78%) | 289 out of 350 recovered (83%) |

: **Example 1**

When we look at the data in example 1, for both men and woman, people who took the drug showed higher recovery rates. However, when you remove the gender information and look at the population recovery rates, people who DID NOT take the drug showed higher recovery rates.

In this example, how do we make conclusions about whether or not a person should take the drug? Should we base our conclusions on the overall population rate? Or, should we base our conclusions off of the men/woman sub-populations?

The authors argue that the answers to these questions can not be found in the data alone. Instead, we must consider the causal mechanism that generated the results of the data. Suppose, that previous studies showed that estrogen negatively impacted recovery rates and that woman are significantly more likely to take the drug than men. Then we can say that being a woman is a common cause of taking the drug and failing to recover. Therefore, we need to compare recovery rates within gender and we should utilize the recovery rates from the men/woman sub populations.

Now consider example 2, the results have the same recovery rates (with drug and no drug switched), but instead or recording gender, post-treatment blood pressure was recorded. Now would we want to use the overall recovery rates, or the stratified recovery rates? What if we knew that the effects recovery rates by lowering blood pressure? Since BP is one of the mechanisms that the drug effects treatment, we would want to use the general population rates.

|           | No Drug                        | Drug                           |
|-----------|--------------------------------|--------------------------------|
| Low BP    | 81 out of 87 recovered (93%)   | 234 out of 270 recovered (87%) |
| High BP   | 192 out of 263 recovered (73%) | 55 out of 80 recovered (69%)   |
| **Total** | 273 out of 350 recovered (78%) | 289 out of 350 recovered (83%) |

: **Example 2**

The purpose of these two examples is to show that the decision to treat was not based on the data alone and required that we utilized information outside of the data. Statistics alone can not uncover the causal story. However, causal inference encompasses a set to tools that can be used to express and interpret causal assumptions. When used as an aid to statistics, we can uncover causal relationships.



## Structural Causal Models
The authors give some ideas about basic probability theory before moving on to the 
introduction of graphs and structural causal models. However, I am going to skip over the introduction to probablity and focus on graphs and SCM. 

### Graphs
When talking about graphs it is easy to think about a collection of visualization
tools which aid in our understanding of trends and patterns. However, in mathematics, graphs have a formal definition. A graph consists of two elements:

1. Nodes - Sometimes called vertices, are often represented as dots or circles. 
2. Edges - Are lines or arrows connecting the dot/circles. 

An example of nodes and edges may be simlar to what is displayed below. The edges
of the graph can be directed (with arrow) or undirected (without and arrow).

```{mermaid}
graph LR;
    A((A))---B((B))
```

```{mermaid}
graph LR;
    C((C))-->D((D))
```

When we have a directed graph and their exists a path from a node to a itself, 
this is referenced to as a cyclic graph. 

```{mermaid}
graph LR;
    A((A)) --> B((B))
    B --> C((C))
    C --> A

```

If no such path exists then this is called an **acyclic graph**. 

```{mermaid}
graph LR;
    A((A)) --> B((B))
    B --> C((C))
    A --> C
```









